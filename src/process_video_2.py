"""
Input: A csv generated by process_video.py
Output: A video showing all detected people's chest point (calculated as the centre of their left shoulder and right shoulder)
"""
#!/usr/bin/env python3
import argparse
import csv
import sys
from collections import defaultdict
import cv2
import numpy as np

# --- CONFIG ---
CSV_COLS = 58
NUM_KEYPOINTS = 17
TARGET_FPS = 30
FULL_DELAY = int(1000 / TARGET_FPS)  # milliseconds per frame
HALF_DELAY = FULL_DELAY // 2
BOX_COLOR = (255, 255, 255)  # White
TEXT_COLOR = (0, 0, 0)     # Black

def read_csv_by_frame(path):
    with open(path, newline="") as f:
        reader = csv.reader(f)
        header = next(reader)

        # Ensure correct number of columns
        if len(header) != CSV_COLS:
            raise ValueError(f"CSV has {len(header)} columns, expected {CSV_COLS}")

        current_frame = None
        batch = []

        for row in reader:
            frame_id = int(row[0])  # frame_id

            if current_frame is None:
                current_frame = frame_id

            if frame_id != current_frame:
                yield current_frame, batch
                batch = []
                current_frame = frame_id

            # Convert row to dict
            id = int(row[1])
            conf = float(row[2])
            box = list(map(float, row[3:7]))
            keypoints = []
            kp_vals = row[7:]

            for i in range(NUM_KEYPOINTS):
                x = float(kp_vals[i*3 + 0])
                y = float(kp_vals[i*3 + 1])
                v = float(kp_vals[i*3 + 2])
                keypoints.append((x, y, v))

            batch.append({
                "id": id,
                "confidence": conf,
                "box": box,  # [x1, y1, x2, y2]
                "keypoints": keypoints
            })

        if batch:
            yield current_frame, batch

def draw_fencer_centrepoints(frame: np.ndarray, detections: list[dict], left_fencer_ids: set[int], right_fencer_ids: set[int]) -> tuple[np.ndarray, list[tuple[int, int, int]]]:
    for det in detections:
            if det["id"] in left_fencer_ids:
                color = (255, 0, 0)  # Blue
            elif det["id"] in right_fencer_ids:
                color = (0, 0, 255)
            else: continue  # Not a person we care about
            x1, y1, x2, y2 = map(int, det["box"])
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            # draw only the centerpoint of shoulder points (6 and 7) https://docs.ultralytics.com/tasks/pose/
            left_shoulder = det["keypoints"][6]
            right_shoulder = det["keypoints"][7]
            if left_shoulder[2] > 0.1 and right_shoulder[2] > 0.1:
                cx = int((left_shoulder[0] + right_shoulder[0]) / 2)
                cy = int((left_shoulder[1] + right_shoulder[1]) / 2)
                cv2.circle(frame, (cx, cy), 3, color, -1)
    return frame

def draw_centrepoints(frame: np.ndarray, detections: list[dict], current_left_fencer_id: int | None, current_right_fencer_id: int | None) -> tuple[np.ndarray, list[tuple[int, int, int]], int | None, int | None]:
    centre_points = []
    new_left_fencer_id = None
    new_right_fencer_id = None
    for det in detections:
        if det["id"] == current_left_fencer_id:
            new_left_fencer_id = det["id"]
        elif det["id"] == current_right_fencer_id:
            new_right_fencer_id = det["id"]
        x1, y1, x2, y2 = map(int, det["box"])
      
        # draw only the centerpoint of shoulder points (6 and 7) https://docs.ultralytics.com/tasks/pose/
        left_shoulder = det["keypoints"][6]
        right_shoulder = det["keypoints"][7]
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(frame, str(det["id"]), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
        cx = int((left_shoulder[0] + right_shoulder[0]) / 2)
        cy = int((left_shoulder[1] + right_shoulder[1]) / 2)
        cv2.circle(frame, (cx, cy), 3, (0, 0, 255), -1)
        centre_points.append((det["id"], cx, cy))

    return frame, centre_points, new_left_fencer_id, new_right_fencer_id

def obtain_fencer_ids(csv_path: str, video_path: str) -> None:
    cap: cv2.VideoCapture = cv2.VideoCapture(video_path)
    slow: bool = False
    early_exit = False

    # Variables to track fencer IDs
    current_left_fencer_id: int | None = None
    current_right_fencer_id: int | None = None
    left_fencer_ids: set[int] = set()
    right_fencer_ids: set[int] = set()
    not_left_fencer_ids = set()
    not_right_fencer_ids = set()

    # Timers to avoid selecting fencers too frequently
    internal_clock = 0
    left_fencer_selection_timer = 0
    right_fencer_selection_timer = 0

    delay: int = HALF_DELAY // 16

    for _, detections in read_csv_by_frame(csv_path):
        ret, frame = cap.read()
        if not ret:
            break
        frame = draw_text_box(frame)
        frame, centrepoints, current_left_fencer_id, current_right_fencer_id = draw_centrepoints(frame, detections, current_left_fencer_id, current_right_fencer_id)

        # select left fencer if not selected and timer passed
        if current_left_fencer_id is None and left_fencer_selection_timer < internal_clock:
            frame, current_left_fencer_id = get_fencer_id(frame, centrepoints, left_fencer_ids, not_left_fencer_ids, left=True)
            if current_left_fencer_id is None:
                print("Left fencer not seen, continuing.")
                left_fencer_selection_timer = internal_clock + 3 * delay 
                continue
            elif current_left_fencer_id == -1:
                print("Quitting.")
                early_exit = True
                break
            left_fencer_ids.add(current_left_fencer_id)
            not_right_fencer_ids.add(current_left_fencer_id)

        # select right fencer if not selected and timer passed
        if current_right_fencer_id is None and right_fencer_selection_timer < internal_clock:
            frame, current_right_fencer_id = get_fencer_id(frame, centrepoints, right_fencer_ids, not_right_fencer_ids, left=False)
            if current_right_fencer_id is None:
                print("Right fencer not seen, continuing.")
                right_fencer_selection_timer = internal_clock + 3 * delay
                continue
            elif current_right_fencer_id == -1:
                print("Quitting.")
                early_exit = True
                break
            right_fencer_ids.add(current_right_fencer_id)
            not_left_fencer_ids.add(current_right_fencer_id)

        # add all detected ids not in left or right fencer ids to not left or right fencer ids
        if current_left_fencer_id is not None and current_right_fencer_id is not None:
            for det in detections:
                if det["id"] not in left_fencer_ids:
                    not_left_fencer_ids.add(det["id"])
                if det["id"] not in right_fencer_ids:
                    not_right_fencer_ids.add(det["id"])

        cv2.imshow("Obtain fencer IDs", frame)

        internal_clock += delay
        key: int = cv2.waitKey(delay) & 0xFF
        if key == ord(' '):          # toggle on space
            slow = not slow
        elif key in (ord('q'), ord('Q'), 27):  # q or Esc to quit
            break

    cap.release()
    cv2.destroyAllWindows()
    return left_fencer_ids, right_fencer_ids, early_exit

def draw_text_box(frame: np.ndarray) -> np.ndarray:
    # draw a white rectangle in the top for instructions
    cv2.rectangle(frame, (0, 0), (int(frame.shape[1]), 100), BOX_COLOR, -1)
    return frame

def get_fencer_id(frame: np.ndarray, centrepoints: list[tuple[int, int, int]], known_ids: set[int], exclude_ids: set[int], left: bool) -> tuple[np.ndarray, int | None]:
    window_name = "Select Fencer ID"
    # click on screen to select fencer, select centrepoint of shoulder points (6 and 7) closest to mouse click
    if not centrepoints:
        return frame, None
    candidates = [det for det in centrepoints if det[0] not in exclude_ids]
    if not candidates:
        return frame, None
    for candidate in candidates:
        if candidate[0] in known_ids:
            return frame, candidate[0]  # if one candidate is already known, return them
    # print(known_ids, exclude_ids)
    fencer_dir = "Left" if left else "Right"
    # frame = draw_text_box(frame)
    # cv2.putText(frame, f"Click on the {fencer_dir} Fencer if their centrepoint is present and press enter to confirm. If not, press '1'.", (0, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, TEXT_COLOR, 2)
    selected_id = None
    def mouse_callback(event, x, y, flags, param):
        nonlocal selected_id
        if event == cv2.EVENT_LBUTTONDOWN:
            closest_det = None
            closest_dist = float('inf')
            for id, cx, cy in candidates:
                if id in exclude_ids:
                    continue
                dist = (cx - x) ** 2 + (cy - y) ** 2
                if dist < closest_dist:
                    closest_dist = dist
                    closest_det = {"id": id, "keypoints": [(cx, cy)]}
            if closest_det:
                selected_id = closest_det["id"]
                print(f"Selected ID: {selected_id}")
    cv2.namedWindow(window_name)
    cv2.setMouseCallback(window_name, mouse_callback)
    while True:
        frame = draw_text_box(frame)
        cv2.putText(frame, f"Click on the {fencer_dir} Fencer if their centrepoint is present and press enter to confirm. If not, press '1'.", (0, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, TEXT_COLOR, 2)
        cv2.putText(frame, f"Selected ID: {selected_id}" if selected_id is not None else "No Fencer Selected", (30, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, TEXT_COLOR, 2)
        cv2.imshow(window_name, frame)
        key = cv2.waitKey(FULL_DELAY) & 0xFF
        if key == 13 and selected_id is not None:  # Fencer selected and Enter pressed
            break
        # if enter pressed but no fencer selected, ignore. nice to have feedback but not essential
        elif key in (27, ord('q'), ord('Q')):
            selected_id = -1  # Signal to quit
            break
        elif key == ord('1'):  # Press '1' to skip
            selected_id = None
            break
    cv2.destroyWindow(window_name)
    return frame, selected_id

def reprocess_csv(input_csv: str, left_fencer_ids: set[int], right_fencer_ids: set[int], output_csv_path: str) -> None:
    with open(output_csv_path, "w") as output_csv:
        with open(input_csv, "r") as input_csv:
            # skip header
            next(input_csv)
            # Process each frame's detections and write to the output CSV
            while input_csv:
                line = input_csv.readline()
                if not line:
                    break
                id = int(line.strip().split(',')[1]) # get id
                if id in left_fencer_ids:
                    fencer_dir = 0  # Left
                elif id in right_fencer_ids:
                    fencer_dir = 1  # Right
                else:
                    continue  # Skip if fencer ID is not recognized
                parts = line.strip().split(',')
                # Replace the fencer ID with 0 for left and 1 for right
                parts[1] = str(fencer_dir)
                line = ','.join(parts) + '\n'
                output_csv.write(line)

def main():
    parser = argparse.ArgumentParser(description="Process CSV with video input")
    parser.add_argument("csv_path", help="Path to results.csv")
    parser.add_argument("video_path", help="Path to input.mp4")
    parser.add_argument("--output", type=str, default=None,
                        help="Output csv folder (default: same as input csv folder)")
    args = parser.parse_args()

    csv_path = args.csv_path
    video_path = args.video_path
    output_path = args.output
    left_fencer_ids, right_fencer_ids, early_exit = obtain_fencer_ids(csv_path, video_path)
    if early_exit:
        print("Exiting early, not outputting csv.")
        return
    
    if output_path is None:
        output_path = csv_path.rsplit('.', 1)[0] + "_with_ids.csv"
    
    reprocess_csv(csv_path, left_fencer_ids, right_fencer_ids, output_path)


if __name__ == "__main__":
    main()

